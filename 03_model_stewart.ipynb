{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617b2b8c",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "For our evaluation metric, we want to use RMSE. RMSE allows us to view the model's error in terms of the target's unit, making it easier to understand. \n",
    "\n",
    "We do intend to use clusters in some of our models, but I'm curious to see how the model performs without the clusters first. When all models have been run, we will compare them to see if the clusters we created improve our models.\n",
    "\n",
    "For the models we will create for our MVP, the features we will be using are `tax_value`, `age`, `sq_ft`, and the clusters we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b708e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import wrangle as w\n",
    "import model_stewart as m\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LassoLars\n",
    "# turn off pink warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c139238a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37170, 9), (15930, 9), (13276, 9))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrangle data\n",
    "train, validate, test = w.split_zillow(w.clean_zillow(w.acquire_zillow()))\n",
    "\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "569a235c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baths</th>\n",
       "      <th>beds</th>\n",
       "      <th>sq_ft</th>\n",
       "      <th>fullbaths</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>tax_value</th>\n",
       "      <th>logerror</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66500</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2326</td>\n",
       "      <td>3</td>\n",
       "      <td>34470765</td>\n",
       "      <td>-118644068</td>\n",
       "      <td>345323.0</td>\n",
       "      <td>0.037484</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13062</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1543</td>\n",
       "      <td>1</td>\n",
       "      <td>34182349</td>\n",
       "      <td>-118356933</td>\n",
       "      <td>185676.0</td>\n",
       "      <td>0.048781</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40001</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1215</td>\n",
       "      <td>2</td>\n",
       "      <td>34099504</td>\n",
       "      <td>-117832092</td>\n",
       "      <td>248535.0</td>\n",
       "      <td>0.064811</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20241</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2082</td>\n",
       "      <td>2</td>\n",
       "      <td>34236827</td>\n",
       "      <td>-118263712</td>\n",
       "      <td>726769.0</td>\n",
       "      <td>-0.024468</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42370</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1895</td>\n",
       "      <td>2</td>\n",
       "      <td>34228050</td>\n",
       "      <td>-118477798</td>\n",
       "      <td>161758.0</td>\n",
       "      <td>-0.532849</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       baths  beds  sq_ft  fullbaths  latitude  longitude  tax_value  \\\n",
       "66500    3.0     4   2326          3  34470765 -118644068   345323.0   \n",
       "13062    1.0     3   1543          1  34182349 -118356933   185676.0   \n",
       "40001    2.0     3   1215          2  34099504 -117832092   248535.0   \n",
       "20241    2.0     4   2082          2  34236827 -118263712   726769.0   \n",
       "42370    2.0     3   1895          2  34228050 -118477798   161758.0   \n",
       "\n",
       "       logerror    age  \n",
       "66500  0.037484   22.0  \n",
       "13062  0.048781   82.0  \n",
       "40001  0.064811   62.0  \n",
       "20241 -0.024468   59.0  \n",
       "42370 -0.532849  103.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33f25d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    37170.000000\n",
       "mean         0.016311\n",
       "std          0.161939\n",
       "min         -4.655420\n",
       "25%         -0.022814\n",
       "50%          0.006473\n",
       "75%          0.036825\n",
       "max          3.394544\n",
       "Name: logerror, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view summary stats for target\n",
    "train.logerror.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f10a91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view logerror distribution\n",
    "train.logerror.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080d822",
   "metadata": {},
   "source": [
    "To establish a baseline, I want to use median rather than mean. Looking at the histogram and summary statistics above, the median seems to be more representative of the data than mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab11d938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0064734128946900005"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# establish baseline\n",
    "baseline = train.logerror.median()\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d4b339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split data into x and y\n",
    "# scaled_cols = ['tax_value', 'age', 'sq_ft']\n",
    "\n",
    "# x_train = train[scaled_cols]\n",
    "# y_train = train.logerror\n",
    "\n",
    "# x_validate = validate[scaled_cols]\n",
    "# y_validate = validate.logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7865115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import eval metric\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # evaluate baseline\n",
    "# y_train = pd.DataFrame(y_train)\n",
    "# y_validate = pd.DataFrame(y_validate)\n",
    "\n",
    "# y_train['baseline'] = baseline\n",
    "# y_validate['baseline'] = baseline\n",
    "\n",
    "# rmse_train = mean_squared_error(y_train.logerror, y_train.baseline)**0.5\n",
    "# rmse_validate = mean_squared_error(y_validate.logerror, y_validate.baseline)**0.5\n",
    "\n",
    "# print('Baseline(median `logerror`) RMSE')\n",
    "# print(f'Train: {rmse_train}')\n",
    "# print(f'Validate: {rmse_validate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c8e8dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run ols model (without clusters)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # create object\n",
    "# lm = LinearRegression(normalize=True)\n",
    "# # fit model to train\n",
    "# lm.fit(x_train, y_train.logerror)\n",
    "# # train predictions\n",
    "# y_train['ols_pred'] = lm.predict(x_train)\n",
    "# # evaluate model on train\n",
    "# rmse_train_ols = mean_squared_error(y_train.logerror, y_train.ols_pred)**0.5\n",
    "# # validate predictions\n",
    "# y_validate['ols_pred'] = lm.predict(x_validate)\n",
    "# # evaluate model on validate\n",
    "# rmse_validate_ols = mean_squared_error(y_validate.logerror, y_validate.ols_pred)**0.5\n",
    "\n",
    "# # print results\n",
    "# print(f'OLS RMSE Train: {rmse_train_ols}')\n",
    "# print(f'OLS RMSE Validate: {rmse_validate_ols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51449305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run lassolars without clusters\n",
    "# from sklearn.linear_model import LassoLars\n",
    "\n",
    "# # create object\n",
    "# lars = LassoLars()\n",
    "# # fit model to train\n",
    "# lars.fit(x_train, y_train.logerror)\n",
    "# # make predictions on train\n",
    "# y_train['ll_pred'] = lars.predict(x_train)\n",
    "# # evaluate model on train\n",
    "# rmse_train_ll = mean_squared_error(y_train.logerror, y_train.ll_pred)**0.5\n",
    "# # validate predictions\n",
    "# y_validate['ll_pred'] = lars.predict(x_validate)\n",
    "# # evaluate model on validate\n",
    "# rmse_validate_ll = mean_squared_error(y_validate.logerror, y_validate.ll_pred)**0.5\n",
    "\n",
    "# # print results\n",
    "# print(f'LassoLars RMSE Train: {rmse_train_ll}')\n",
    "# print(f'LassoLars RMSE Validate: {rmse_validate_ll}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cda9772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # view results as dataframe\n",
    "# rmse = pd.DataFrame({'Linear Regression':[rmse_train_ols, rmse_validate_ols, (rmse_train_ols-rmse_validate_ols)],\n",
    "#                     'LassoLars':[rmse_train_ll, rmse_validate_ll, (rmse_train_ll-rmse_validate_ll)],\n",
    "#                     'Baseline':[rmse_train, rmse_validate, (rmse_train-rmse_validate)]},\n",
    "#                     index=['train', 'validate', 'difference'])\n",
    "# rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83da03",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "- Without using any of the clusters we made in exploration, the Polynomial Regression model appears to perform best. \n",
    " - This model has the lowest RMSE for both train and validate, and it has the smallest difference between train/validate RMSE. \n",
    "- All of the models created so far in this notebook have beaten the baseline (median logerror) by a very small margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "118c1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use selectkbest to get top features\n",
    "# from sklearn.feature_selection import SelectKBest, f_regression\n",
    "# # set parameters for f_selector object\n",
    "# f_selector = SelectKBest(f_regression, k=2)\n",
    "# # fit object to data\n",
    "# f_selector.fit(x_train, y_train.logerror)\n",
    "# # get bool mask of features list\n",
    "# f_mask = f_selector.get_support()\n",
    "# # get list of features (True)\n",
    "# f_feature = x_train.iloc[:,f_mask].columns.tolist()\n",
    "# f_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "338342a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test = m.scale_and_cluster(train, validate, test, ['sq_ft', 'tax_value', 'age'], ['beds', 'baths', 'sq_ft'], 4)\n",
    "X_train, X_validate, X_test = m.encode_clusters(X_train, X_validate, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90046a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sq_ft</th>\n",
       "      <th>tax_value</th>\n",
       "      <th>age</th>\n",
       "      <th>cluster_0</th>\n",
       "      <th>cluster_1</th>\n",
       "      <th>cluster_2</th>\n",
       "      <th>cluster_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.009680</td>\n",
       "      <td>-0.130520</td>\n",
       "      <td>-1.371333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.118375</td>\n",
       "      <td>-0.807491</td>\n",
       "      <td>1.274529</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.590919</td>\n",
       "      <td>-0.540942</td>\n",
       "      <td>0.392575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.658153</td>\n",
       "      <td>1.486974</td>\n",
       "      <td>0.260282</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.388746</td>\n",
       "      <td>-0.908914</td>\n",
       "      <td>2.200581</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37165</th>\n",
       "      <td>0.127982</td>\n",
       "      <td>0.301724</td>\n",
       "      <td>0.877650</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37166</th>\n",
       "      <td>0.162558</td>\n",
       "      <td>-0.187142</td>\n",
       "      <td>0.833552</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37167</th>\n",
       "      <td>-0.962615</td>\n",
       "      <td>-0.695815</td>\n",
       "      <td>-0.798063</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37168</th>\n",
       "      <td>0.102050</td>\n",
       "      <td>-0.445465</td>\n",
       "      <td>0.613064</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37169</th>\n",
       "      <td>-0.288376</td>\n",
       "      <td>-0.382639</td>\n",
       "      <td>0.789455</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37170 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sq_ft  tax_value       age  cluster_0  cluster_1  cluster_2  \\\n",
       "0      1.009680  -0.130520 -1.371333          0          0          1   \n",
       "1     -0.118375  -0.807491  1.274529          0          0          0   \n",
       "2     -0.590919  -0.540942  0.392575          0          1          0   \n",
       "3      0.658153   1.486974  0.260282          0          1          0   \n",
       "4      0.388746  -0.908914  2.200581          0          1          0   \n",
       "...         ...        ...       ...        ...        ...        ...   \n",
       "37165  0.127982   0.301724  0.877650          0          1          0   \n",
       "37166  0.162558  -0.187142  0.833552          0          1          0   \n",
       "37167 -0.962615  -0.695815 -0.798063          1          0          0   \n",
       "37168  0.102050  -0.445465  0.613064          0          1          0   \n",
       "37169 -0.288376  -0.382639  0.789455          0          1          0   \n",
       "\n",
       "       cluster_3  \n",
       "0              0  \n",
       "1              1  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "37165          0  \n",
       "37166          0  \n",
       "37167          0  \n",
       "37168          0  \n",
       "37169          0  \n",
       "\n",
       "[37170 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e187953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_and_cluster(train, validate, test, model_vars, cluster_vars, k):\n",
    "#     '''\n",
    "#     This function takes in a list of variables to be modeled on, a list of features to\n",
    "#     cluster by, and a k-value to determine the number of clusters to create.\n",
    "#     It returns train, validate, and test dataframes with a cluster column, as well as scaled versions\n",
    "#     of train, validate, and test with a cluster column.\n",
    "#     '''\n",
    "#     from sklearn.preprocessing import StandardScaler\n",
    "#     from sklearn.cluster import KMeans\n",
    "#     # define independent variables\n",
    "#     X_train = pd.concat([train[model_vars], train[cluster_vars]], axis=1)\n",
    "#     X_train = X_train.loc[:,~X_train.columns.duplicated()]\n",
    "#     X_validate = pd.concat([validate[model_vars], validate[cluster_vars]], axis=1)\n",
    "#     X_validate = X_validate.loc[:,~X_validate.columns.duplicated()]\n",
    "#     X_test = pd.concat([test[model_vars], test[cluster_vars]], axis=1)\n",
    "#     X_test = X_test.loc[:,~X_test.columns.duplicated()]\n",
    "#     # scale features\n",
    "#     scaler = StandardScaler().fit(X_train)\n",
    "#     X_scaled_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\n",
    "#     X_scaled_validate = pd.DataFrame(scaler.transform(X_validate), columns = X_validate.columns)\n",
    "#     X_scaled_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "#     # create kmeans object\n",
    "#     kmeans = KMeans(n_clusters=k, random_state=123)\n",
    "#     # fit object\n",
    "#     kmeans.fit(X_scaled_train[cluster_vars])\n",
    "#     # make predictions\n",
    "#     kmeans.predict(X_scaled_train[cluster_vars])\n",
    "#     # create columns for predictions\n",
    "#     train['cluster'] = kmeans.predict(X_scaled_train[cluster_vars])\n",
    "#     X_scaled_train['cluster'] = kmeans.predict(X_scaled_train[cluster_vars])\n",
    "#     validate['cluster'] = kmeans.predict(X_scaled_validate[cluster_vars])\n",
    "#     X_scaled_validate['cluster'] = kmeans.predict(X_scaled_validate[cluster_vars])\n",
    "#     test['cluster'] = kmeans.predict(X_scaled_test[cluster_vars])\n",
    "#     X_scaled_test['cluster'] = kmeans.predict(X_scaled_test[cluster_vars])\n",
    "#     model_vars.append('cluster')\n",
    "#     X_train = X_scaled_train[model_vars]\n",
    "#     X_validate = X_scaled_validate[model_vars]\n",
    "#     X_test = X_scaled_test[model_vars]\n",
    "#     return X_train, X_validate, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a3aa182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_validate, X_test = scale_and_cluster(train, validate, test, ['tax_value', 'age', 'sq_ft'], ['beds', 'baths', 'sq_ft'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deb74c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_clusters(X_train, X_validate, X_test):\n",
    "#     '''\n",
    "# This function takes in scaled X_train/validate/test dfs and encodes the cluster column. Dropping the \n",
    "# original unencoded cluster column.\n",
    "#     '''\n",
    "    \n",
    "#     #encode cluster column\n",
    "#     dummy_train_df = pd.get_dummies(X_train.cluster, prefix='cluster_')\n",
    "#     dummy_validate_df = pd.get_dummies(X_validate.cluster, prefix='cluster_')\n",
    "#     dummy_test_df = pd.get_dummies(X_test.cluster, prefix='cluster_')\n",
    "    \n",
    "#     encoded_train = pd.concat([X_train , dummy_train_df], axis = 1)\n",
    "#     encoded_validate = pd.concat([X_validate , dummy_validate_df], axis = 1)\n",
    "#     encoded_test = pd.concat([X_test , dummy_test_df], axis = 1)\n",
    "    \n",
    "#     X_train_encoded = encoded_train.drop(columns = ['cluster'])\n",
    "#     X_validate_encoded = encoded_validate.drop(columns = ['cluster'])\n",
    "#     X_test_encoded = encoded_test.drop(columns = ['cluster'])\n",
    "        \n",
    "#     return X_train_encoded, X_validate_encoded, X_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adb9dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_validate, X_test = scale_and_cluster(train, validate, test, ['tax_value', 'age', 'sq_ft'], ['beds', 'baths', 'sq_ft'], 4)\n",
    "# X_train, X_validate, X_test = encode_clusters(X_train, X_validate, X_test)\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b414c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_features(target, X_scaled_train, X_scaled_validate, X_scaled_test, y_train, y_validate, y_test):\n",
    "#     #baseline_prediction\n",
    "#     median = y_train[target].median()\n",
    "#     y_train['baseline_pred'] = median\n",
    "#     y_validate['baseline_pred'] = median\n",
    "   \n",
    "#     rmse_baseline_train = mean_squared_error(y_train[target], y_train.baseline_pred)**(1/2)\n",
    "#     rmse_baseline_validate = mean_squared_error(y_train[target], y_train.baseline_pred)**(1/2)\n",
    "   \n",
    "#     print('Baseline RSME')\n",
    "#     print(f'rmse_baseline_train: {rmse_baseline_train}')\n",
    "#     print(f'rmse_baseline_validate: {rmse_baseline_validate}')\n",
    "#     print()\n",
    "\n",
    "# # plt.hist(y_train[target], color='blue', alpha=.5, label=f'{target.upper()}')\n",
    "# #    plt.hist(y_train['baseline_pred'], bins=1, color='red', alpha=.5, rwidth=100, label=f'Predicted {target.upper()}')\n",
    "# #    plt.xlabel(f'{target.upper()}')\n",
    "# #    plt.legend()\n",
    "# #    plt.show();\n",
    "   \n",
    "#    #model01_prediction\n",
    "#     lm = LinearRegression(normalize=True)\n",
    "#     lm.fit(X_scaled_train, y_train[target])\n",
    "   \n",
    "#     y_train['model01_pred'] = lm.predict(X_scaled_train)\n",
    "#     y_validate['model01_pred'] = lm.predict(X_scaled_validate)\n",
    "   \n",
    "#     rsme_model01_train = (mean_squared_error(y_train.logerror, y_train['model01_pred']))**(1/2)\n",
    "#     rsme_model01_validate = (mean_squared_error(y_validate.logerror, y_validate['model01_pred']))**(1/2)\n",
    "   \n",
    "#     print('Model 01 | Linear Reg OLS RMSE')\n",
    "#     print(f'rmse_model01_train: {rsme_model01_train}')\n",
    "#     print(f'rmse_model01_validate: {rsme_model01_validate}')   \n",
    "#     print()\n",
    "   \n",
    "#    # model02_prediction\n",
    "#     lars = LassoLars(alpha=1.0)\n",
    "#     lars.fit(X_scaled_train, y_train[target])\n",
    "   \n",
    "#     y_train['model02_pred'] = lars.predict(X_scaled_train)\n",
    "#     y_validate['model02_pred'] = lars.predict(X_scaled_validate)\n",
    "   \n",
    "#     rsme_model02_train = (mean_squared_error(y_train.logerror, y_train['model02_pred']))**(1/2)\n",
    "#     rsme_model02_validate = (mean_squared_error(y_validate.logerror, y_validate['model02_pred']))**(1/2)\n",
    "   \n",
    "#     print('Model 02 | LassoLars RMSE')\n",
    "#     print(f'rmse_model02_train: {rsme_model02_train}')\n",
    "#     print(f'rmse_model02_validate: {rsme_model02_validate}')   \n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b1dd800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_features('logerror', X_train[['tax_value', 'age', 'sq_ft']], X_validate[['tax_value', 'age', 'sq_ft']], X_test[['tax_value', 'age', 'sq_ft']], pd.DataFrame(train.logerror), pd.DataFrame(validate.logerror), pd.DataFrame(test.logerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c5feaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_features('logerror', X_train, X_validate, X_test, pd.DataFrame(train.logerror), pd.DataFrame(validate.logerror), pd.DataFrame(test.logerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbab8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y\n",
    "# y_train = pd.DataFrame(train.logerror)\n",
    "# y_validate = pd.DataFrame(validate.logerror)\n",
    "# y_test = pd.DataFrame(test.logerror)\n",
    "\n",
    "# # run ols with clusters\n",
    "# # create object\n",
    "# lm = LinearRegression(normalize=True)\n",
    "# # fit model to train\n",
    "# lm.fit(X_train, y_train)\n",
    "# # train predictions\n",
    "# y_train['ols_pred'] = lm.predict(X_train)\n",
    "# # evaluate model on train\n",
    "# rmse_train_ols_cl = mean_squared_error(y_train.logerror, y_train.ols_pred)**0.5\n",
    "# # validate predictions\n",
    "# y_validate['ols_pred'] = lm.predict(X_validate)\n",
    "# # evaluate model on validate\n",
    "# rmse_validate_ols_cl = mean_squared_error(y_validate.logerror, y_validate.ols_pred)**0.5\n",
    "\n",
    "# # print results\n",
    "# print(f'OLS RMSE Train: {rmse_train_ols_cl}')\n",
    "# print(f'OLS RMSE Validate: {rmse_validate_ols_cl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4061dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run ols without clusters\n",
    "# create object\n",
    "# lm = LinearRegression(normalize=True)\n",
    "# # fit model to train\n",
    "# lm.fit(X_train[['tax_value', 'age', 'sq_ft']], y_train)\n",
    "# # train predictions\n",
    "# y_train['ols_pred'] = lm.predict(X_train[['tax_value', 'age', 'sq_ft']])\n",
    "# # evaluate model on train\n",
    "# rmse_train_ols = mean_squared_error(y_train.logerror, y_train.ols_pred)**0.5\n",
    "# # validate predictions\n",
    "# y_validate['ols_pred'] = lm.predict(X_validate[['tax_value', 'age', 'sq_ft']])\n",
    "# # evaluate model on validate\n",
    "# rmse_validate_ols = mean_squared_error(y_validate.logerror, y_validate.ols_pred)**0.5\n",
    "\n",
    "# # print results\n",
    "# print(f'OLS RMSE Train: {rmse_train_ols}')\n",
    "# print(f'OLS RMSE Validate: {rmse_validate_ols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d316bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run lassolars with clusters\n",
    "# from sklearn.linear_model import LassoLars\n",
    "\n",
    "# # create object\n",
    "# lars = LassoLars()\n",
    "# # fit model to train\n",
    "# lars.fit(X_train, y_train.logerror)\n",
    "# # make predictions on train\n",
    "# y_train['ll_pred'] = lars.predict(X_train)\n",
    "# # evaluate model on train\n",
    "# rmse_train_ll_cl = mean_squared_error(y_train.logerror, y_train.ll_pred)**0.5\n",
    "# # validate predictions\n",
    "# y_validate['ll_pred'] = lars.predict(X_validate)\n",
    "# # evaluate model on validate\n",
    "# rmse_validate_ll_cl = mean_squared_error(y_validate.logerror, y_validate.ll_pred)**0.5\n",
    "\n",
    "# # print results\n",
    "# print(f'LassoLars RMSE Train: {rmse_train_ll_cl}')\n",
    "# print(f'LassoLars RMSE Validate: {rmse_validate_ll_cl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7b1f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run lassolars without clusters\n",
    "# from sklearn.linear_model import LassoLars\n",
    "\n",
    "# # create object\n",
    "# lars = LassoLars()\n",
    "# # fit model to train\n",
    "# lars.fit(X_train[['tax_value', 'age', 'sq_ft']], y_train.logerror)\n",
    "# # make predictions on train\n",
    "# y_train['ll_pred'] = lars.predict(X_train[['tax_value', 'age', 'sq_ft']])\n",
    "# # evaluate model on train\n",
    "# rmse_train_ll = mean_squared_error(y_train.logerror, y_train.ll_pred)**0.5\n",
    "# # validate predictions\n",
    "# y_validate['ll_pred'] = lars.predict(X_validate[['tax_value', 'age', 'sq_ft']])\n",
    "# # evaluate model on validate\n",
    "# rmse_validate_ll = mean_squared_error(y_validate.logerror, y_validate.ll_pred)**0.5\n",
    "\n",
    "# # print results\n",
    "# print(f'LassoLars RMSE Train: {rmse_train_ll}')\n",
    "# print(f'LassoLars RMSE Validate: {rmse_validate_ll}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c423ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view results as dataframe\n",
    "# rmse = pd.DataFrame({'OLS with Clusters':[rmse_train_ols_cl, rmse_validate_ols_cl, (rmse_train_ols_cl-rmse_validate_ols_cl)],\n",
    "#                      'OLS without Clusters':[rmse_train_ols, rmse_validate_ols, (rmse_train_ols-rmse_validate_ols)],\n",
    "#                      'LassoLars with Clusters':[rmse_train_ll_cl, rmse_validate_ll_cl, (rmse_train_ll_cl-rmse_validate_ll_cl)],\n",
    "#                      'LassoLars without Clusters':[rmse_train_ll, rmse_validate_ll, (rmse_train_ll-rmse_validate_ll)],\n",
    "#                      'Baseline':[rmse_train, rmse_validate, (rmse_train-rmse_validate)]},\n",
    "#                     index=['train', 'validate', 'difference'])\n",
    "# rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da62b5",
   "metadata": {},
   "source": [
    "Based on the results of our models, it appears the OLS models performed best. Of those, \n",
    "- both models performed better on validate than on train\n",
    "- the model with clusters performed better on the train set\n",
    "- the model without clusters performed better on the validate set\n",
    "- there was less of a difference between train and validate for the OLS model with clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f556ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_features_df(target, X_scaled_train, X_scaled_validate, X_scaled_test, y_train, y_validate, y_test, model_vars):\n",
    "# #baseline_prediction\n",
    "#     median = y_train[target].median()\n",
    "#     y_train['baseline_pred'] = median\n",
    "#     y_validate['baseline_pred'] = median\n",
    "   \n",
    "#     rmse_baseline_train = mean_squared_error(y_train[target], y_train.baseline_pred)**(1/2)\n",
    "#     rmse_baseline_validate = mean_squared_error(y_validate[target], y_validate.baseline_pred)**(1/2)\n",
    "\n",
    "#    #model01_prediction\n",
    "#     lm = LinearRegression(normalize=True)\n",
    "#     lm.fit(X_scaled_train, y_train[target])\n",
    "   \n",
    "#     y_train['model01_pred'] = lm.predict(X_scaled_train)\n",
    "#     y_validate['model01_pred'] = lm.predict(X_scaled_validate)\n",
    "   \n",
    "#     rsme_model01_train = (mean_squared_error(y_train.logerror, y_train['model01_pred']))**(1/2)\n",
    "#     rsme_model01_validate = (mean_squared_error(y_validate.logerror, y_validate['model01_pred']))**(1/2)\n",
    "   \n",
    "#     #model02_prediction\n",
    "#     lars = LassoLars(alpha=1.0)\n",
    "#     lars.fit(X_scaled_train, y_train[target])\n",
    "   \n",
    "#     y_train['model02_pred'] = lars.predict(X_scaled_train)\n",
    "#     y_validate['model02_pred'] = lars.predict(X_scaled_validate)\n",
    "   \n",
    "#     rsme_model02_train = (mean_squared_error(y_train.logerror, y_train['model02_pred']))**(1/2)\n",
    "#     rsme_model02_validate = (mean_squared_error(y_validate.logerror, y_validate['model02_pred']))**(1/2)\n",
    "\n",
    "    \n",
    "#     #model03_prediction\n",
    "#     lm = LinearRegression(normalize=True)\n",
    "#     lm.fit(X_scaled_train[model_vars], y_train[target])\n",
    "   \n",
    "#     y_train['model03_pred'] = lm.predict(X_scaled_train[model_vars])\n",
    "#     y_validate['model03_pred'] = lm.predict(X_scaled_validate[model_vars])\n",
    "   \n",
    "#     rsme_model03_train = (mean_squared_error(y_train.logerror, y_train['model03_pred']))**(1/2)\n",
    "#     rsme_model03_validate = (mean_squared_error(y_validate.logerror, y_validate['model03_pred']))**(1/2)\n",
    "    \n",
    "#     #model04_prediction\n",
    "#     lars.fit(X_scaled_train[model_vars], y_train[target])\n",
    "   \n",
    "#     y_train['model04_pred'] = lars.predict(X_scaled_train[model_vars])\n",
    "#     y_validate['model04_pred'] = lars.predict(X_scaled_validate[model_vars])\n",
    "   \n",
    "#     rsme_model04_train = (mean_squared_error(y_train.logerror, y_train['model04_pred']))**(1/2)\n",
    "#     rsme_model04_validate = (mean_squared_error(y_validate.logerror, y_validate['model04_pred']))**(1/2)\n",
    "   \n",
    "#     return pd.DataFrame({'OLS with Clusters':[rsme_model01_train, rsme_model01_validate, (rsme_model01_train-rsme_model01_validate)],\n",
    "#                      'OLS without Clusters':[rsme_model03_train, rsme_model03_validate, (rsme_model03_train-rsme_model03_validate)],\n",
    "#                      'LassoLars with Clusters':[rsme_model02_train, rsme_model02_validate, (rsme_model02_train-rsme_model02_validate)],\n",
    "#                      'LassoLars without Clusters':[rsme_model04_train, rsme_model04_validate, (rsme_model04_train-rsme_model04_validate)],\n",
    "#                      'Baseline':[rmse_baseline_train, rmse_baseline_validate, (rmse_baseline_train-rmse_baseline_validate)]},\n",
    "#                     index=['train', 'validate', 'difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d00b242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLS with Clusters</th>\n",
       "      <th>OLS without Clusters</th>\n",
       "      <th>LassoLars with Clusters</th>\n",
       "      <th>LassoLars without Clusters</th>\n",
       "      <th>Baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.161743</td>\n",
       "      <td>0.161749</td>\n",
       "      <td>0.161937</td>\n",
       "      <td>0.161937</td>\n",
       "      <td>0.162235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validate</th>\n",
       "      <td>0.161144</td>\n",
       "      <td>0.161163</td>\n",
       "      <td>0.161371</td>\n",
       "      <td>0.161371</td>\n",
       "      <td>0.161686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>difference</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OLS with Clusters  OLS without Clusters  LassoLars with Clusters  \\\n",
       "train                0.161743              0.161749                 0.161937   \n",
       "validate             0.161144              0.161163                 0.161371   \n",
       "difference           0.000599              0.000586                 0.000566   \n",
       "\n",
       "            LassoLars without Clusters  Baseline  \n",
       "train                         0.161937  0.162235  \n",
       "validate                      0.161371  0.161686  \n",
       "difference                    0.000566  0.000550  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.model_features_df_report(X_train, X_validate, pd.DataFrame(train.logerror), pd.DataFrame(validate.logerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3acb6e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>M01</th>\n",
       "      <th>M02</th>\n",
       "      <th>M03</th>\n",
       "      <th>M04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66500</th>\n",
       "      <td>0.037484</td>\n",
       "      <td>-0.031010</td>\n",
       "      <td>-0.011116</td>\n",
       "      <td>-0.021173</td>\n",
       "      <td>-0.014053</td>\n",
       "      <td>-0.021173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13062</th>\n",
       "      <td>0.048781</td>\n",
       "      <td>-0.042308</td>\n",
       "      <td>-0.029250</td>\n",
       "      <td>-0.032470</td>\n",
       "      <td>-0.027332</td>\n",
       "      <td>-0.032470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40001</th>\n",
       "      <td>0.064811</td>\n",
       "      <td>-0.058338</td>\n",
       "      <td>-0.049186</td>\n",
       "      <td>-0.048500</td>\n",
       "      <td>-0.050516</td>\n",
       "      <td>-0.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20241</th>\n",
       "      <td>-0.024468</td>\n",
       "      <td>0.030942</td>\n",
       "      <td>0.036187</td>\n",
       "      <td>0.040779</td>\n",
       "      <td>0.040149</td>\n",
       "      <td>0.040779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42370</th>\n",
       "      <td>-0.532849</td>\n",
       "      <td>0.539323</td>\n",
       "      <td>0.560193</td>\n",
       "      <td>0.549160</td>\n",
       "      <td>0.561065</td>\n",
       "      <td>0.549160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25859</th>\n",
       "      <td>-0.002734</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>0.019336</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>0.020410</td>\n",
       "      <td>0.019045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65786</th>\n",
       "      <td>-0.003675</td>\n",
       "      <td>0.010149</td>\n",
       "      <td>0.023207</td>\n",
       "      <td>0.019986</td>\n",
       "      <td>0.023890</td>\n",
       "      <td>0.019986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63812</th>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>0.010950</td>\n",
       "      <td>0.015542</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.015542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54132</th>\n",
       "      <td>-0.008501</td>\n",
       "      <td>0.014975</td>\n",
       "      <td>0.028032</td>\n",
       "      <td>0.024812</td>\n",
       "      <td>0.028981</td>\n",
       "      <td>0.024812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>-0.017066</td>\n",
       "      <td>0.023540</td>\n",
       "      <td>0.034644</td>\n",
       "      <td>0.033377</td>\n",
       "      <td>0.034073</td>\n",
       "      <td>0.033377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37170 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual  Baseline       M01       M02       M03       M04\n",
       "66500  0.037484 -0.031010 -0.011116 -0.021173 -0.014053 -0.021173\n",
       "13062  0.048781 -0.042308 -0.029250 -0.032470 -0.027332 -0.032470\n",
       "40001  0.064811 -0.058338 -0.049186 -0.048500 -0.050516 -0.048500\n",
       "20241 -0.024468  0.030942  0.036187  0.040779  0.040149  0.040779\n",
       "42370 -0.532849  0.539323  0.560193  0.549160  0.561065  0.549160\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "25859 -0.002734  0.009208  0.019336  0.019045  0.020410  0.019045\n",
       "65786 -0.003675  0.010149  0.023207  0.019986  0.023890  0.019986\n",
       "63812  0.000769  0.005705  0.010950  0.015542  0.008693  0.015542\n",
       "54132 -0.008501  0.014975  0.028032  0.024812  0.028981  0.024812\n",
       "310   -0.017066  0.023540  0.034644  0.033377  0.034073  0.033377\n",
       "\n",
       "[37170 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals = pd.DataFrame({'actual':train.logerror,\n",
    "                  'Baseline':train.logerror.median()-train.logerror,\n",
    "                  'M01':LinearRegression(normalize=True).fit(X_train, train.logerror)\n",
    ".predict(X_train)-train.logerror,\n",
    "                  'M02':LassoLars().fit(X_train, train.logerror).predict(X_train)-train.logerror,\n",
    "                  'M03':LinearRegression(normalize=True).fit(X_train[['tax_value', 'age', 'sq_ft']], train.logerror)\n",
    ".predict(X_train[['tax_value', 'age', 'sq_ft']])-train.logerror,\n",
    "                  'M04':LassoLars().fit(X_train[['tax_value', 'age', 'sq_ft']], train.logerror).predict(X_train[['tax_value', 'age', 'sq_ft']])-train.logerror})\n",
    "\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.scatterplot(data=residuals.drop(columns='actual'))\n",
    "# plt.axhline(y=0, ls=':')\n",
    "# plt.ylabel('residual')\n",
    "# plt.title('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ac6a447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 RMSE Test: 0.15505267621952407\n"
     ]
    }
   ],
   "source": [
    "#model01_prediction\n",
    "y_train = train.logerror\n",
    "lm = LinearRegression(normalize=True)\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "y_test = pd.DataFrame(test.logerror)\n",
    "y_test['model01_pred'] = lm.predict(X_test)\n",
    "   \n",
    "rmse_model01_test = (mean_squared_error(y_test.logerror, y_test['model01_pred']))**(1/2)\n",
    "\n",
    "print(f'Model 1 RMSE Test: {rmse_model01_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9dd16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
